services:
  gmi:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        USER_ID: ${LOCAL_UID:-1000}
        GROUP_ID: ${LOCAL_GID:-1000}
    image: gmi-image
    container_name: gmi-container
    volumes:
      - /home/staticct/matt/workspace:/workspace
      - /home/staticct/data:/data
    working_dir: /workspace
    environment:
      # - PYTHONPATH=/workspace
      # needed for ct_laboratory install
      - TORCH_CUDA_ARCH_LIST=8.0
      - CUDA_HOME=/usr/local/cuda
      # needed for kagglehub datasets to go to /data/
      - KAGGLEHUB_CACHE=/data/kagglehub_cache
    # Enable GPU support if available
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu] 