"""
LLaVA-Med Analysis of ChestMNIST Dataset

This script applies LLaVA-Med to analyze ChestMNIST images for medical findings.
The pipeline includes:
1. Loading ChestMNIST dataset (64x64 grayscale chest X-rays)
2. Upsampling images to higher resolution for LLaVA-Med (configurable)
3. Converting grayscale images to RGB format for vision model
4. Applying LLaVA-Med for medical image analysis and label verification
5. Comparing LLaVA-Med predictions with ground truth labels

ChestMNIST contains 14 binary labels for multi-label classification:
- atelectasis, cardiomegaly, effusion, infiltration, mass, nodule, pneumonia,
- pneumothorax, consolidation, edema, emphysema, fibrosis, pleural, hernia
"""

import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from pathlib import Path
import json
import os
from typing import Dict, List, Tuple, Optional, Union
from tqdm import tqdm
import warnings

import gmi

# Suppress warnings
warnings.filterwarnings("ignore")

# Import our LLaVA-Med pipeline
import sys
sys.path.append('/workspace/gmi/examples/llava_med')
from llava_med import LLaVAMedPipeline

class ChestMNISTLLaVAMedAnalyzer:
    """
    Analyzer that applies LLaVA-Med to ChestMNIST images for medical analysis.
    """
    
    def __init__(self, 
                 upsampled_size: int = 128,
                 original_size: int = 64,
                 batch_size: int = 16,
                 device: Optional[str] = None):
        """
        Initialize the ChestMNIST LLaVA-Med analyzer.
        
        Args:
            upsampled_size: Target size for upsampling (default: 128)
            original_size: Original ChestMNIST size (default: 64)
            batch_size: Batch size for processing (default: 16)
            device: Device to use ('cuda', 'cpu', or None for auto)
        """
        self.upsampled_size = upsampled_size
        self.original_size = original_size
        self.batch_size = batch_size
        self.device = device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        
        # ChestMNIST label codebook
        self.chest_codebook = {
            0: 'atelectasis',
            1: 'cardiomegaly', 
            2: 'effusion',
            3: 'infiltration',
            4: 'mass',
            5: 'nodule',
            6: 'pneumonia',
            7: 'pneumothorax',
            8: 'consolidation',
            9: 'edema',
            10: 'emphysema',
            11: 'fibrosis',
            12: 'pleural',
            13: 'hernia'
        }\n        \n        # Medical condition descriptions for better LLaVA-Med prompts\n        self.condition_descriptions = {\n            'atelectasis': 'collapsed or incomplete expansion of lung tissue',\n            'cardiomegaly': 'enlarged heart',\n            'effusion': 'fluid in pleural space around lungs',\n            'infiltration': 'abnormal substances in lung tissue',\n            'mass': 'abnormal growth or tumor in chest',\n            'nodule': 'small round growth in lungs',\n            'pneumonia': 'infection causing inflammation in lungs',\n            'pneumothorax': 'collapsed lung due to air in pleural space',\n            'consolidation': 'lung tissue filled with liquid instead of air',\n            'edema': 'excess fluid in lungs',\n            'emphysema': 'damage to air sacs in lungs',\n            'fibrosis': 'scarring and thickening of lung tissue',\n            'pleural': 'conditions affecting pleura (lung lining)',\n            'hernia': 'organ pushing through weak muscle or tissue'\n        }\n        \n        # Setup data root\n        self.data_root = '/workspace/gmi/gmi_data/datasets/medmnist_dataset_root/'\n        os.makedirs(self.data_root, exist_ok=True)\n        \n        # Setup output directory\n        self.output_dir = Path('/workspace/gmi/examples/llava_med/chestmnist_analysis')\n        self.output_dir.mkdir(exist_ok=True)\n        \n        print(f\"üîß Initializing ChestMNIST LLaVA-Med Analyzer\")\n        print(f\"   Original size: {original_size}x{original_size}\")\n        print(f\"   Upsampled size: {upsampled_size}x{upsampled_size}\")\n        print(f\"   Device: {self.device}\")\n        print(f\"   Output directory: {self.output_dir}\")\n        \n        # Initialize components\n        self._load_datasets()\n        self._setup_transforms()\n        self._initialize_llava_med()\n    \n    def _load_datasets(self):\n        \"\"\"Load ChestMNIST datasets.\"\"\"\n        print(\"üì• Loading ChestMNIST datasets...\")\n        \n        self.dataset_train = gmi.datasets.MedMNIST(\n            'ChestMNIST',\n            split='train',\n            root=self.data_root,\n            size=self.original_size,\n            download=True\n        )\n        \n        self.dataset_val = gmi.datasets.MedMNIST(\n            'ChestMNIST',\n            split='val', \n            root=self.data_root,\n            size=self.original_size,\n            download=True\n        )\n        \n        self.dataset_test = gmi.datasets.MedMNIST(\n            'ChestMNIST',\n            split='test',\n            root=self.data_root,\n            size=self.original_size,\n            download=True\n        )\n        \n        print(f\"   Train: {len(self.dataset_train)} samples\")\n        print(f\"   Val: {len(self.dataset_val)} samples\")\n        print(f\"   Test: {len(self.dataset_test)} samples\")\n        \n        # Analyze sample\n        sample_img, sample_label = self.dataset_train[0]\n        print(f\"   Sample image shape: {sample_img.shape}\")\n        print(f\"   Sample label shape: {sample_label.shape}\")\n        print(f\"   Image range: [{sample_img.min():.3f}, {sample_img.max():.3f}]\")\n    \n    def _setup_transforms(self):\n        \"\"\"Setup image transforms for upsampling and format conversion.\"\"\"\n        print(f\"üîÑ Setting up transforms for {self.original_size}‚Üí{self.upsampled_size} upsampling\")\n        \n        # Transform to upsample grayscale images to RGB format for LLaVA-Med\n        self.transform = transforms.Compose([\n            # Ensure tensor is in correct format and range\n            transforms.Lambda(lambda x: torch.clamp(x, 0, 1) if isinstance(x, torch.Tensor) else x),\n            \n            # Convert to PIL Image for transforms\n            transforms.ToPILImage(mode='L'),  # Grayscale mode\n            \n            # Upsample using bilinear interpolation\n            transforms.Resize(\n                size=(self.upsampled_size, self.upsampled_size),\n                interpolation=transforms.InterpolationMode.BILINEAR,\n                antialias=True\n            ),\n            \n            # Convert to RGB (duplicate grayscale to 3 channels)\n            transforms.Lambda(lambda img: img.convert('RGB')),\n            \n            # Convert back to tensor if needed\n            transforms.ToTensor(),\n        ])\n        \n        # Alternative transform that keeps as PIL Image for LLaVA-Med\n        self.transform_pil = transforms.Compose([\n            # Ensure tensor is in correct format and range\n            transforms.Lambda(lambda x: torch.clamp(x, 0, 1) if isinstance(x, torch.Tensor) else x),\n            \n            # Convert to PIL Image\n            transforms.ToPILImage(mode='L'),\n            \n            # Upsample using bilinear interpolation\n            transforms.Resize(\n                size=(self.upsampled_size, self.upsampled_size),\n                interpolation=transforms.InterpolationMode.BILINEAR,\n                antialias=True\n            ),\n            \n            # Convert to RGB\n            transforms.Lambda(lambda img: img.convert('RGB')),\n        ])\n    \n    def _initialize_llava_med(self):\n        \"\"\"Initialize LLaVA-Med pipeline.\"\"\"\n        print(\"ü§ñ Initializing LLaVA-Med pipeline...\")\n        try:\n            self.llava_pipeline = LLaVAMedPipeline(device=self.device)\n            print(\"‚úÖ LLaVA-Med pipeline initialized\")\n        except Exception as e:\n            print(f\"‚ö†Ô∏è  LLaVA-Med initialization issue: {e}\")\n            print(\"   Continuing with framework demo mode\")\n            self.llava_pipeline = LLaVAMedPipeline(device=self.device)\n    \n    def process_single_image(self, \n                           image: torch.Tensor, \n                           label: torch.Tensor, \n                           idx: int) -> Dict:\n        \"\"\"\n        Process a single ChestMNIST image with LLaVA-Med.\n        \n        Args:\n            image: ChestMNIST image tensor [1, H, W]\n            label: Multi-label binary tensor [14]\n            idx: Sample index\n            \n        Returns:\n            Dictionary with analysis results\n        \"\"\"\n        # Convert to PIL Image for LLaVA-Med\n        pil_image = self.transform_pil(image)\n        \n        # Get ground truth conditions\n        gt_conditions = [self.chest_codebook[i] for i, val in enumerate(label) if val == 1]\n        \n        # Create comprehensive medical prompt\n        base_prompt = (\n            \"You are analyzing a chest X-ray image. Please provide a detailed medical analysis including: \"\n            \"1) Overall image quality and view, \"\n            \"2) Anatomical structures visible, \"\n            \"3) Any abnormalities or pathological findings, \"\n            \"4) Specific conditions that may be present from this list: \"\n            f\"{', '.join(self.chest_codebook.values())}. \"\n            \"Please be specific about what you observe.\"\n        )\n        \n        # Alternative focused prompt\n        focused_prompt = (\n            f\"This is a chest X-ray. Look for signs of: {', '.join(self.chest_codebook.values())}. \"\n            \"Which of these conditions, if any, are visible in this image? \"\n            \"Explain your findings.\"\n        )\n        \n        # Verification prompt based on ground truth\n        if gt_conditions:\n            verification_prompt = (\n                f\"This chest X-ray has been labeled with: {', '.join(gt_conditions)}. \"\n                \"Do you see evidence of these conditions? Please analyze each one specifically.\"\n            )\n        else:\n            verification_prompt = (\n                \"This chest X-ray has been labeled as normal (no pathological findings). \"\n                \"Do you agree? What do you observe in this image?\"\n            )\n        \n        results = {\n            'idx': idx,\n            'gt_conditions': gt_conditions,\n            'gt_labels': label.tolist(),\n            'image_shape': pil_image.size,\n            'analyses': {}\n        }\n        \n        # Run multiple analyses with different prompts\n        prompts = {\n            'comprehensive': base_prompt,\n            'focused': focused_prompt,\n            'verification': verification_prompt\n        }\n        \n        for prompt_name, prompt_text in prompts.items():\n            try:\n                print(f\"   Running {prompt_name} analysis...\")\n                response = self.llava_pipeline.analyze_image(\n                    image=pil_image,\n                    question=prompt_text,\n                    max_new_tokens=300,\n                    temperature=0.1\n                )\n                results['analyses'][prompt_name] = {\n                    'prompt': prompt_text,\n                    'response': response\n                }\n            except Exception as e:\n                print(f\"   ‚ö†Ô∏è  {prompt_name} analysis failed: {e}\")\n                results['analyses'][prompt_name] = {\n                    'prompt': prompt_text,\n                    'response': f\"Analysis failed: {str(e)}\"\n                }\n        \n        return results\n    \n    def analyze_dataset_sample(self, \n                             dataset_split: str = 'test',\n                             num_samples: int = 10,\n                             start_idx: int = 0) -> List[Dict]:\n        \"\"\"\n        Analyze a sample of images from the dataset.\n        \n        Args:\n            dataset_split: Which split to use ('train', 'val', 'test')\n            num_samples: Number of samples to analyze\n            start_idx: Starting index in dataset\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        dataset = getattr(self, f'dataset_{dataset_split}')\n        print(f\"üìä Analyzing {num_samples} samples from {dataset_split} set (starting at {start_idx})\")\n        \n        results = []\n        \n        for i in tqdm(range(start_idx, min(start_idx + num_samples, len(dataset))), \n                     desc=f\"Analyzing {dataset_split} samples\"):\n            image, label = dataset[i]\n            \n            print(f\"\\nüîç Processing sample {i}\")\n            print(f\"   Ground truth: {[self.chest_codebook[j] for j, val in enumerate(label) if val == 1]}\")\n            \n            result = self.process_single_image(image, label, i)\n            results.append(result)\n            \n            # Save intermediate results\n            if (i - start_idx + 1) % 5 == 0:\n                self._save_results(results, f\"{dataset_split}_sample_{start_idx}_{i}.json\")\n        \n        # Save final results\n        self._save_results(results, f\"{dataset_split}_analysis_{start_idx}_{start_idx + len(results) - 1}.json\")\n        \n        return results\n    \n    def analyze_by_condition(self, \n                           condition: str,\n                           dataset_split: str = 'test',\n                           max_samples: int = 5) -> List[Dict]:\n        \"\"\"\n        Analyze samples that have a specific condition.\n        \n        Args:\n            condition: Condition name from chest_codebook\n            dataset_split: Which dataset split to use\n            max_samples: Maximum number of samples to analyze\n            \n        Returns:\n            List of analysis results\n        \"\"\"\n        if condition not in self.chest_codebook.values():\n            raise ValueError(f\"Condition '{condition}' not in codebook: {list(self.chest_codebook.values())}\")\n        \n        # Find condition index\n        condition_idx = [k for k, v in self.chest_codebook.items() if v == condition][0]\n        \n        dataset = getattr(self, f'dataset_{dataset_split}')\n        print(f\"üéØ Analyzing samples with condition: {condition} (index {condition_idx})\")\n        \n        # Find samples with this condition\n        matching_samples = []\n        for i, (image, label) in enumerate(dataset):\n            if label[condition_idx] == 1:\n                matching_samples.append(i)\n                if len(matching_samples) >= max_samples:\n                    break\n        \n        print(f\"   Found {len(matching_samples)} samples with {condition}\")\n        \n        results = []\n        for i in tqdm(matching_samples, desc=f\"Analyzing {condition} samples\"):\n            image, label = dataset[i]\n            print(f\"\\nüîç Processing {condition} sample {i}\")\n            \n            result = self.process_single_image(image, label, i)\n            results.append(result)\n        \n        # Save results\n        self._save_results(results, f\"{dataset_split}_{condition}_analysis.json\")\n        \n        return results\n    \n    def create_analysis_visualization(self, \n                                    results: List[Dict],\n                                    save_path: Optional[str] = None) -> None:\n        \"\"\"\n        Create visualization of analysis results.\n        \n        Args:\n            results: List of analysis results\n            save_path: Path to save visualization\n        \"\"\"\n        fig, axes = plt.subplots(len(results), 2, figsize=(15, 5 * len(results)))\n        if len(results) == 1:\n            axes = axes.reshape(1, -1)\n        \n        for i, result in enumerate(results):\n            # Get original image for visualization\n            dataset = self.dataset_test  # Assume test for now\n            image, label = dataset[result['idx']]\n            \n            # Show original image\n            axes[i, 0].imshow(image.squeeze(), cmap='gray')\n            axes[i, 0].set_title(f\"Sample {result['idx']} - Ground Truth: {', '.join(result['gt_conditions']) or 'Normal'}\")\n            axes[i, 0].axis('off')\n            \n            # Show upsampled image\n            upsampled_pil = self.transform_pil(image)\n            axes[i, 1].imshow(upsampled_pil)\n            axes[i, 1].set_title(f\"Upsampled to {self.upsampled_size}x{self.upsampled_size}\")\n            axes[i, 1].axis('off')\n            \n            # Add text with analysis results\n            analysis_text = \"\"\n            for analysis_type, analysis_data in result['analyses'].items():\n                analysis_text += f\"\\n{analysis_type.upper()}:\\n\"\n                analysis_text += analysis_data['response'][:200] + \"...\\n\"\n            \n            # Add text below the images\n            fig.text(0.1, 0.9 - (i + 1) * 0.9 / len(results), analysis_text, \n                    fontsize=8, ha='left', va='top', wrap=True)\n        \n        plt.tight_layout()\n        \n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n            print(f\"üìä Visualization saved to: {save_path}\")\n        \n        plt.show()\n    \n    def _save_results(self, results: List[Dict], filename: str) -> None:\n        \"\"\"\n        Save analysis results to JSON file.\n        \n        Args:\n            results: List of analysis results\n            filename: Output filename\n        \"\"\"\n        output_path = self.output_dir / filename\n        \n        # Convert any numpy arrays to lists for JSON serialization\n        serializable_results = []\n        for result in results:\n            serializable_result = result.copy()\n            if isinstance(serializable_result.get('gt_labels'), np.ndarray):\n                serializable_result['gt_labels'] = serializable_result['gt_labels'].tolist()\n            serializable_results.append(serializable_result)\n        \n        with open(output_path, 'w') as f:\n            json.dump(serializable_results, f, indent=2)\n        \n        print(f\"üíæ Results saved to: {output_path}\")\n    \n    def generate_summary_report(self, results: List[Dict]) -> Dict:\n        \"\"\"\n        Generate summary report of analysis results.\n        \n        Args:\n            results: List of analysis results\n            \n        Returns:\n            Summary statistics\n        \"\"\"\n        print(\"üìà Generating summary report...\")\n        \n        summary = {\n            'total_samples': len(results),\n            'condition_distribution': {},\n            'analysis_types': list(results[0]['analyses'].keys()) if results else [],\n            'samples_by_condition': {}\n        }\n        \n        # Analyze condition distribution\n        for condition_name in self.chest_codebook.values():\n            samples_with_condition = [\n                r for r in results \n                if condition_name in r['gt_conditions']\n            ]\n            summary['condition_distribution'][condition_name] = len(samples_with_condition)\n            summary['samples_by_condition'][condition_name] = [\n                r['idx'] for r in samples_with_condition\n            ]\n        \n        # Count normal samples (no conditions)\n        normal_samples = [r for r in results if not r['gt_conditions']]\n        summary['normal_samples'] = len(normal_samples)\n        \n        return summary\n\n\ndef main():\n    \"\"\"\n    Main function to demonstrate ChestMNIST LLaVA-Med analysis.\n    \"\"\"\n    print(\"üè• ChestMNIST LLaVA-Med Analysis\")\n    print(\"=\" * 50)\n    \n    # Configuration\n    config = {\n        'upsampled_size': 128,  # Can be changed to 256, 512, etc.\n        'original_size': 64,\n        'batch_size': 16,\n        'device': None  # Auto-detect\n    }\n    \n    print(f\"Configuration:\")\n    for key, value in config.items():\n        print(f\"  {key}: {value}\")\n    \n    # Initialize analyzer\n    analyzer = ChestMNISTLLaVAMedAnalyzer(**config)\n    \n    # Test 1: Analyze a few random samples\n    print(\"\\n\" + \"=\" * 50)\n    print(\"TEST 1: Random Sample Analysis\")\n    print(\"=\" * 50)\n    \n    random_results = analyzer.analyze_dataset_sample(\n        dataset_split='test',\n        num_samples=3,\n        start_idx=0\n    )\n    \n    # Test 2: Analyze samples with specific conditions\n    print(\"\\n\" + \"=\" * 50)\n    print(\"TEST 2: Condition-Specific Analysis\")\n    print(\"=\" * 50)\n    \n    # Analyze pneumonia cases\n    try:\n        pneumonia_results = analyzer.analyze_by_condition(\n            condition='pneumonia',\n            dataset_split='test',\n            max_samples=2\n        )\n    except Exception as e:\n        print(f\"Pneumonia analysis failed: {e}\")\n        pneumonia_results = []\n    \n    # Test 3: Generate summary and visualization\n    print(\"\\n\" + \"=\" * 50)\n    print(\"TEST 3: Summary and Visualization\")\n    print(\"=\" * 50)\n    \n    all_results = random_results + pneumonia_results\n    \n    if all_results:\n        # Generate summary\n        summary = analyzer.generate_summary_report(all_results)\n        print(\"\\nSummary Report:\")\n        print(json.dumps(summary, indent=2))\n        \n        # Create visualization\n        try:\n            analyzer.create_analysis_visualization(\n                results=all_results[:3],  # First 3 results\n                save_path=analyzer.output_dir / \"analysis_visualization.png\"\n            )\n        except Exception as e:\n            print(f\"Visualization failed: {e}\")\n    \n    print(\"\\n‚úÖ ChestMNIST LLaVA-Med analysis completed!\")\n    print(f\"   Results saved in: {analyzer.output_dir}\")\n\n\nif __name__ == \"__main__\":\n    main()\n