diff --git a/README.md b/README.md
index 2bc3183..04951c7 100644
--- a/README.md
+++ b/README.md
@@ -110,10 +110,44 @@ gmi_base/                          # Root directory (git clone location)
         ‚îî‚îÄ‚îÄ visualizations/        # Generated visualizations
 ```
 
-## üê≥ Docker Usage
+## üê≥ Docker Development Environment
 
-### Starting the Container
+This project uses a Docker container for a controlled development environment. The container is already running and contains all necessary dependencies. We develop the GMI package by editing files on the host system and testing them inside the container.
 
+### Key Concepts
+
+- **Host System**: Your local machine where you edit files
+- **Docker Container**: Running environment with all dependencies
+- **No Rebuilding**: The container is already set up and running
+- **Live Development**: Edit files on host, test immediately in container
+
+### Container Setup and Architecture
+
+The GMI container is built from `nvidia/cuda:12.8.1-cudnn-runtime-ubuntu22.04` and includes:
+- Python 3.12 with PyTorch 12.8 (CUDA support)
+- All GMI dependencies from `requirements.txt`
+- GMI package installed in editable mode (`pip install -e .`)
+- Non-root user (`gmi_user`) with proper file permissions
+- Working directory: `/gmi_base` (maps to your project root)
+
+### Volume Mounting
+The `docker-compose.yml` mounts your local project directory to `/gmi_base` in the container:
+- Host: `./` (your project root)
+- Container: `/gmi_base`
+- Changes on host are immediately available in container
+
+### GPU Support
+The container is configured with NVIDIA GPU support:
+- Uses NVIDIA Docker runtime
+- All GPUs are available to the container
+- CUDA 12.8.1 with cuDNN support
+
+### Container Management
+
+#### Container Status
+The container is already running and ready to use. You don't need to rebuild or restart it.
+
+#### Starting the Container (if needed)
 ```bash
 # Build and start the container
 docker compose up -d
@@ -122,35 +156,83 @@ docker compose up -d
 docker compose ps
 ```
 
-### Executing Commands
+### Running Commands
+
+#### Option 1: From Outside Container (Docker Exec)
+
+Use this when you're working from your host system and want to execute commands inside the container.
 
 ```bash
-# Run a single command
-docker exec gmi-container python -c "import gmi; print('GMI loaded successfully!')"
+# Execute commands inside the running container
+docker exec -it gmi-container <command>
+
+# Examples:
+docker exec -it gmi-container python main.py --help
+docker exec -it gmi-container python examples/modular_configs/run_default_study.py
+docker exec -it gmi-container bash examples/modular_configs/run_all_studies_cli.sh
+```
 
-# Start an interactive shell
+#### Option 2: From Inside Container
+
+Use this when you're already inside the container (e.g., through an interactive session).
+
+```bash
+# Start interactive bash session
 docker exec -it gmi-container bash
 
-# Run the visualization script (downloads all datasets)
-docker exec gmi-container bash examples/visualize_all_datasets/visualize_all_datasets.sh
+# Or start interactive Python session
+docker exec -it gmi-container python
+```
 
-# Run a specific example
-docker exec gmi-container python examples/test_reconstruction_yaml.py
+#### Common Commands
+```bash
+# Test import
+docker exec -it gmi-container python -c "import gmi; print('Package loaded successfully')"
+
+# Test CLI help
+docker exec -it gmi-container python main.py --help
+
+# Test specific command
+docker exec -it gmi-container python main.py train-image-reconstructor examples/modular_configs/training_config.yaml --experiment-name test
+
+# Run example scripts
+docker exec -it gmi-container python examples/modular_configs/run_default_study.py
+docker exec -it gmi-container python examples/modular_configs/run_all_modular_studies.py
+docker exec -it gmi-container bash examples/modular_configs/run_all_studies_cli.sh
 ```
 
-### Data Persistence
+### Development Workflow
 
-The `gmi_data/` directory is mounted as a volume, so:
-- Downloaded datasets persist between container restarts
-- Model checkpoints are saved to `gmi_data/models/`
-- Visualizations are saved to `gmi_data/outputs/visualizations/`
+1. **Edit Files**: Edit GMI package files on your host system
+2. **Test Changes**: Run tests inside the container to verify changes
+3. **Debug Issues**: Use stack traces to identify and fix problems
+4. **Run Examples**: Once components work, run full examples
 
-### GPU Support
+### Debugging Tips
+
+```bash
+# Check container status
+docker ps
+
+# Check container logs
+docker logs gmi-container
+
+# Interactive debugging
+docker exec -it gmi-container python
+docker exec -it gmi-container bash
+
+# Check GPU availability
+docker exec -it gmi-container nvidia-smi
+docker exec -it gmi-container python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
+```
+
+### Troubleshooting
+
+- **Container Not Responding**: `docker restart gmi-container`
+- **Permission Issues**: Check file permissions with `docker exec -it gmi-container ls -la /gmi_base/`
+- **Memory Issues**: Monitor with `docker stats gmi-container`
 
-The Docker configuration includes NVIDIA GPU support. Ensure you have:
-- NVIDIA Docker runtime installed
-- Compatible NVIDIA drivers
-- Docker configured for GPU access
+This development environment provides a controlled, reproducible setup for developing and testing the GMI package. The key is to understand that you're editing on the host but testing in the container, and the `docker exec` command is your bridge between the two.
 
 ## üéØ Core Features
 
diff --git a/gmi/__init__.py b/gmi/__init__.py
index 0839bf7..d3063fd 100644
--- a/gmi/__init__.py
+++ b/gmi/__init__.py
@@ -1,6 +1,7 @@
 # /gmi/gmi/__init__.py: Initializes the gmi package
 
 from . import linalg
+from . import linear_operator
 from . import samplers
 from . import distribution
 from . import sde
diff --git a/gmi/commands/train_diffusion_model.py b/gmi/commands/train_diffusion_model.py
index 350ee94..5a73f19 100644
--- a/gmi/commands/train_diffusion_model.py
+++ b/gmi/commands/train_diffusion_model.py
@@ -4,12 +4,11 @@ Command for training diffusion models from YAML configuration.
 
 import yaml
 import torch
-import argparse
 from pathlib import Path
 from typing import Dict, Any, List, Union, Optional
 
 from ..diffusion.core import DiffusionModel
-from ..config import load_components_from_dict, load_and_merge_configs, load_object_from_dict
+from ..config import load_and_merge_configs, load_object_from_dict
 
 
 def train_diffusion_model_from_configs(config_paths: List[Union[str, Path]], 
diff --git a/gmi/diffusion/core.py b/gmi/diffusion/core.py
index d49820f..c095ed2 100644
--- a/gmi/diffusion/core.py
+++ b/gmi/diffusion/core.py
@@ -645,6 +645,224 @@ class DiffusionModel(torch.nn.Module):
         
         return summary_stats
 
+    def train_diffusion_model_from_config(self, config_dict, device=None, experiment_name=None, output_dir=None):
+        """
+        Train the diffusion model using a configuration dictionary.
+        
+        Args:
+            config_dict: Configuration dictionary containing training parameters
+            device: Device to use (default: auto-detect)
+            experiment_name: Override experiment name from config
+            output_dir: Override output directory from config
+            
+        Returns:
+            Tuple of (train_losses, val_losses, eval_metrics)
+        """
+        from ..config import load_object_from_dict
+        
+        # Extract components from config
+        train_dataset = config_dict.get('train_dataset')
+        validation_dataset = config_dict.get('validation_dataset')
+        test_dataset = config_dict.get('test_dataset')
+        diffusion_backbone = config_dict.get('diffusion_backbone')
+        
+        # Extract diffusion-specific components
+        forward_SDE = config_dict.get('forward_SDE')
+        training_loss_fn = config_dict.get('training_loss_fn')
+        training_time_sampler = config_dict.get('training_time_sampler')
+        training_time_uncertainty_sampler = config_dict.get('training_time_uncertainty_sampler')
+        
+        # Load components if they are config dictionaries
+        if isinstance(train_dataset, dict):
+            train_dataset = load_object_from_dict(train_dataset)
+        if isinstance(validation_dataset, dict):
+            validation_dataset = load_object_from_dict(validation_dataset)
+        if isinstance(test_dataset, dict):
+            test_dataset = load_object_from_dict(test_dataset)
+        if isinstance(diffusion_backbone, dict):
+            diffusion_backbone = load_object_from_dict(diffusion_backbone)
+        
+        # Load diffusion-specific components if they are config dictionaries
+        if isinstance(forward_SDE, dict):
+            forward_SDE = load_object_from_dict(forward_SDE)
+        if isinstance(training_loss_fn, dict):
+            training_loss_fn = load_object_from_dict(training_loss_fn)
+        if isinstance(training_time_sampler, dict):
+            training_time_sampler = load_object_from_dict(training_time_sampler)
+        if isinstance(training_time_uncertainty_sampler, dict):
+            training_time_uncertainty_sampler = load_object_from_dict(training_time_uncertainty_sampler)
+        
+        # Use train_dataset as the main dataset
+        dataset = train_dataset
+        
+        if not all([dataset, diffusion_backbone]):
+            raise ValueError("Configuration must contain 'train_dataset' and 'diffusion_backbone'")
+        
+        # Set device
+        if device is None:
+            device = 'cuda' if torch.cuda.is_available() else 'cpu'
+        
+        print(f"Using device: {device}")
+        if device == 'cuda':
+            print(f"GPU: {torch.cuda.get_device_name(0)}")
+        
+        # Move diffusion backbone to device if it's not already
+        if hasattr(diffusion_backbone, 'to'):
+            diffusion_backbone = diffusion_backbone.to(device)
+        
+        # Get experiment name
+        if experiment_name is None:
+            experiment_name = config_dict.get('experiment_name', 'unnamed_diffusion_experiment')
+        
+        # Determine output directory
+        if output_dir is None:
+            output_dir = config_dict.get('output_dir', f"gmi_data/outputs/{experiment_name}")
+        
+        print(f"Starting training for experiment: {experiment_name}")
+        
+        # Create diffusion model with optional components
+        diffusion_model = DiffusionModel(
+            diffusion_backbone=diffusion_backbone,
+            forward_SDE=forward_SDE,
+            training_loss_fn=training_loss_fn,
+            training_time_sampler=training_time_sampler,
+            training_time_uncertainty_sampler=training_time_uncertainty_sampler
+        )
+        
+        # Extract training configuration
+        training_config = config_dict.get('training', {})
+        
+        # Explicitly cast numeric values to correct types
+        def to_int(val, default):
+            try:
+                return int(val)
+            except Exception:
+                return int(default)
+        def to_float(val, default):
+            try:
+                return float(val)
+            except Exception:
+                return float(default)
+        
+        # Cast all relevant fields
+        num_epochs = to_int(training_config.get('num_epochs', 100), 100)
+        num_iterations_train = to_int(training_config.get('num_iterations_train', 100), 100)
+        num_iterations_val = to_int(training_config.get('num_iterations_val', 10), 10)
+        num_iterations_test = to_int(training_config.get('num_iterations_test', 1), 1)
+        learning_rate = to_float(training_config.get('learning_rate', 0.001), 0.001)
+        batch_size = to_int(training_config.get('batch_size', 4), 4)
+        num_workers = to_int(training_config.get('num_workers', 4), 4)
+        patience = to_int(training_config.get('patience', 10), 10)
+        val_loss_smoothing = to_float(training_config.get('val_loss_smoothing', 0.9), 0.9)
+        min_delta = to_float(training_config.get('min_delta', 1e-6), 1e-6)
+        ema_decay = to_float(training_config.get('ema_decay', 0.999), 0.999)
+        test_plot_vmin = to_float(training_config.get('test_plot_vmin', 0), 0)
+        test_plot_vmax = to_float(training_config.get('test_plot_vmax', 1), 1)
+        reverse_t_start = to_float(training_config.get('reverse_t_start', 1.0), 1.0)
+        reverse_t_end = to_float(training_config.get('reverse_t_end', 0.0), 0.0)
+        reverse_timesteps = to_int(training_config.get('reverse_timesteps', 50), 50)
+        
+        # Train the model with training config
+        train_losses, val_losses, eval_metrics = diffusion_model.train_diffusion_model(
+            dataset=dataset,
+            val_data=validation_dataset,
+            test_data=test_dataset,
+            experiment_name=experiment_name,
+            output_dir=output_dir,
+            num_epochs=num_epochs,
+            num_iterations_train=num_iterations_train,
+            num_iterations_val=num_iterations_val,
+            num_iterations_test=num_iterations_test,
+            learning_rate=learning_rate,
+            train_batch_size=batch_size,
+            val_batch_size=batch_size,
+            test_batch_size=batch_size,
+            train_num_workers=num_workers,
+            val_num_workers=num_workers,
+            test_num_workers=num_workers,
+            shuffle_train=training_config.get('shuffle_train', True),
+            shuffle_val=training_config.get('shuffle_val', True),
+            shuffle_test=training_config.get('shuffle_test', False),
+            use_ema=training_config.get('use_ema', True),
+            ema_decay=ema_decay,
+            early_stopping=training_config.get('early_stopping', True),
+            patience=patience,
+            val_loss_smoothing=val_loss_smoothing,
+            min_delta=min_delta,
+            verbose=training_config.get('verbose', True),
+            very_verbose=training_config.get('very_verbose', False),
+            wandb_project=training_config.get('wandb_project', None),
+            wandb_config=training_config.get('wandb_config', None),
+            save_checkpoints=training_config.get('save_checkpoints', True),
+            test_plot_vmin=test_plot_vmin,
+            test_plot_vmax=test_plot_vmax,
+            test_save_plots=training_config.get('test_save_plots', True),
+            final_test_iterations=training_config.get('final_test_iterations', 'all'),
+            reverse_t_start=reverse_t_start,
+            reverse_t_end=reverse_t_end,
+            reverse_spacing=training_config.get('reverse_spacing', 'linear'),
+            reverse_sampler=training_config.get('reverse_sampler', 'euler'),
+            reverse_timesteps=reverse_timesteps
+        )
+        
+        print(f"Training completed!")
+        print(f"Final train loss: {train_losses[-1]:.4f}")
+        if val_losses:
+            print(f"Final validation loss: {val_losses[-1]:.4f}")
+        
+        return train_losses, val_losses, eval_metrics
+
+    @classmethod
+    def train_from_config_file(cls, config_path, device=None, experiment_name=None, output_dir=None):
+        """
+        Train a diffusion model from a YAML configuration file.
+        
+        Args:
+            config_path: Path to YAML configuration file
+            device: Device to use (default: auto-detect)
+            experiment_name: Override experiment name from config
+            output_dir: Override output directory from config
+            
+        Returns:
+            Tuple of (train_losses, val_losses, eval_metrics)
+        """
+        import yaml
+        from pathlib import Path
+        from ..config import load_object_from_dict
+        
+        # Load configuration file
+        config_path = Path(config_path)
+        if not config_path.exists():
+            raise FileNotFoundError(f"Configuration file not found: {config_path}")
+        
+        with open(config_path, 'r') as f:
+            config_dict = yaml.safe_load(f)
+        
+        # Extract diffusion backbone from config
+        diffusion_backbone = config_dict.get('diffusion_backbone')
+        if diffusion_backbone is None:
+            raise ValueError("Configuration must contain 'diffusion_backbone'")
+        
+        # Load diffusion backbone if it's a config dictionary
+        if isinstance(diffusion_backbone, dict):
+            diffusion_backbone = load_object_from_dict(diffusion_backbone)
+        
+        # Set device
+        if device is None:
+            device = 'cuda' if torch.cuda.is_available() else 'cpu'
+        
+        # Move diffusion backbone to device
+        if hasattr(diffusion_backbone, 'to'):
+            diffusion_backbone = diffusion_backbone.to(device)
+        
+        # Create diffusion model
+        diffusion_model = cls(diffusion_backbone=diffusion_backbone)
+        
+        # Train using the config
+        return diffusion_model.train_diffusion_model_from_config(
+            config_dict, device, experiment_name, output_dir
+        )
+
 class DiffusionBackbone(torch.nn.Module):
     def __init__(self,
                  x_t_encoder,
diff --git a/main.py b/main.py
index 91e9ad0..59fc79c 100644
--- a/main.py
+++ b/main.py
@@ -75,16 +75,26 @@ def train_image_reconstructor(config, device, experiment_name, train_dataset, va
     """
     from gmi.commands.train_image_reconstructor import train_image_reconstructor_from_configs
     
+    # Define input variables directly (no argument parsing)
+    config_paths = [config]
+    device = device
+    experiment_name = experiment_name
+    train_dataset_path = train_dataset
+    validation_dataset_path = validation_dataset
+    test_dataset_path = test_dataset
+    measurement_simulator_path = measurement_simulator
+    image_reconstructor_path = image_reconstructor
+    
     # Call the command function with all arguments
     train_image_reconstructor_from_configs(
-        config_paths=[config],
+        config_paths=config_paths,
         device=device,
         experiment_name=experiment_name,
-        train_dataset_path=train_dataset,
-        validation_dataset_path=validation_dataset,
-        test_dataset_path=test_dataset,
-        measurement_simulator_path=measurement_simulator,
-        image_reconstructor_path=image_reconstructor
+        train_dataset_path=train_dataset_path,
+        validation_dataset_path=validation_dataset_path,
+        test_dataset_path=test_dataset_path,
+        measurement_simulator_path=measurement_simulator_path,
+        image_reconstructor_path=image_reconstructor_path
     )
 
 # Add the train_diffusion_model command
@@ -115,15 +125,24 @@ def train_diffusion_model(config, device, experiment_name, train_dataset, valida
     """
     from gmi.commands.train_diffusion_model import train_diffusion_model_from_configs
     
+    # Define input variables directly (no argument parsing)
+    config_paths = [config]
+    device = device
+    experiment_name = experiment_name
+    train_dataset_path = train_dataset
+    validation_dataset_path = validation_dataset
+    test_dataset_path = test_dataset
+    diffusion_backbone_path = diffusion_backbone
+    
     # Call the command function with all arguments
     train_diffusion_model_from_configs(
-        config_paths=[config],
+        config_paths=config_paths,
         device=device,
         experiment_name=experiment_name,
-        train_dataset_path=train_dataset,
-        validation_dataset_path=validation_dataset,
-        test_dataset_path=test_dataset,
-        diffusion_backbone_path=diffusion_backbone
+        train_dataset_path=train_dataset_path,
+        validation_dataset_path=validation_dataset_path,
+        test_dataset_path=test_dataset_path,
+        diffusion_backbone_path=diffusion_backbone_path
     )
 
 # Add the evaluate_image_reconstructor command
diff --git a/prompt.md b/prompt.md
deleted file mode 100644
index 336f2da..0000000
--- a/prompt.md
+++ /dev/null
@@ -1,301 +0,0 @@
-# GMI Development Guide
-
-## Overview
-
-This project uses a Docker container for a controlled development environment. The container is already running and contains all necessary dependencies. We develop the GMI package by editing files on the host system and testing them inside the container.
-
-## Key Concepts
-
-- **Host System**: Your local machine where you edit files
-- **Docker Container**: Running environment with all dependencies
-- **No Rebuilding**: The container is already set up and running
-- **Live Development**: Edit files on host, test immediately in container
-
-## Container Setup and Architecture
-
-### Container Configuration
-The GMI container is built from `nvidia/cuda:12.8.1-cudnn-runtime-ubuntu22.04` and includes:
-- Python 3.12 with PyTorch 12.8 (CUDA support)
-- All GMI dependencies from `requirements.txt`
-- GMI package installed in editable mode (`pip install -e .`)
-- Non-root user (`gmi_user`) with proper file permissions
-- Working directory: `/gmi_base` (maps to your project root)
-
-### Volume Mounting
-The `docker-compose.yml` mounts your local project directory to `/gmi_base` in the container:
-- Host: `./` (your project root)
-- Container: `/gmi_base`
-- Changes on host are immediately available in container
-
-### GPU Support
-The container is configured with NVIDIA GPU support:
-- Uses NVIDIA Docker runtime
-- All GPUs are available to the container
-- CUDA 12.8.1 with cuDNN support
-
-### Environment Variables
-- `PYTHONPATH=/gmi_base` - Ensures Python can find the GMI package
-- User permissions match host system (UID/GID from environment)
-
-## Container Management
-
-### Container Status
-The container is already running and ready to use. You don't need to rebuild or restart it.
-
-### Starting the Container (if needed)
-```bash
-# Build and start the container
-docker compose up -d
-
-# Check container status
-docker compose ps
-```
-
-## Running Commands
-
-### Option 1: From Outside Container (Docker Exec)
-
-Use this when you're working from your host system and want to execute commands inside the container.
-
-#### Accessing the Container
-```bash
-# Execute commands inside the running container
-docker exec -it gmi-container <command>
-
-# Examples:
-docker exec -it gmi-container python main.py --help
-docker exec -it gmi-container python examples/modular_configs/run_default_study.py
-docker exec -it gmi-container bash examples/modular_configs/run_all_studies_cli.sh
-```
-
-#### Why Docker Exec?
-- `docker exec` runs commands inside the existing container
-- `-it` provides interactive terminal with proper formatting
-- Changes to files on the host are immediately available in the container
-- No need to rebuild or restart the container
-
-#### Common Commands (Docker Exec)
-```bash
-# Test import
-docker exec -it gmi-container python -c "import gmi; print('Package loaded successfully')"
-
-# Test specific module
-docker exec -it gmi-container python -c "from gmi.commands.train_image_reconstructor import train_image_reconstructor_from_configs"
-
-# Test dataset
-docker exec -it gmi-container python -c "from gmi.datasets.mnist import MNIST; dataset = MNIST(); print(f'Dataset size: {len(dataset)}')"
-
-# Test CLI help
-docker exec -it gmi-container python main.py --help
-
-# Test specific command
-docker exec -it gmi-container python main.py train-image-reconstructor examples/modular_configs/training_config.yaml --experiment-name test
-
-# Run example scripts
-docker exec -it gmi-container python examples/modular_configs/run_default_study.py
-docker exec -it gmi-container python examples/modular_configs/run_all_modular_studies.py
-docker exec -it gmi-container bash examples/modular_configs/run_all_studies_cli.sh
-```
-
-### Option 2: From Inside Container
-
-Use this when you're already inside the container (e.g., through an interactive session) and want to run commands directly.
-
-#### Starting an Interactive Session
-```bash
-# Start interactive bash session
-docker exec -it gmi-container bash
-
-# Or start interactive Python session
-docker exec -it gmi-container python
-```
-
-#### Running Commands Inside Container
-Once inside the container, you can run commands directly without `docker exec`:
-
-```bash
-# Test import
-python -c "import gmi; print('Package loaded successfully')"
-
-# Test specific module
-python -c "from gmi.commands.train_image_reconstructor import train_image_reconstructor_from_configs"
-
-# Test dataset
-python -c "from gmi.datasets.mnist import MNIST; dataset = MNIST(); print(f'Dataset size: {len(dataset)}')"
-
-# Test CLI help
-python main.py --help
-
-# Test specific command
-python main.py train-image-reconstructor examples/modular_configs/training_config.yaml --experiment-name test
-
-# Run example scripts
-python examples/modular_configs/run_default_study.py
-python examples/modular_configs/run_all_modular_studies.py
-bash examples/modular_configs/run_all_studies_cli.sh
-```
-
-## Development Workflow
-
-### 1. Edit Files
-Edit GMI package files on your host system:
-- `gmi/` - Main package code
-- `examples/` - Example scripts and configs
-- `main.py` - CLI entry point
-
-### 2. Test Changes
-Run tests inside the container to verify changes:
-
-**From outside container:**
-```bash
-# Test a single component
-docker exec -it gmi-container python -c "from gmi.datasets.mnist import MNIST; print('MNIST works!')"
-
-# Test CLI command
-docker exec -it gmi-container python main.py train-image-reconstructor examples/modular_configs/training_config.yaml
-
-# Test example script
-docker exec -it gmi-container python examples/modular_configs/run_default_study.py
-```
-
-**From inside container:**
-```bash
-# Test a single component
-python -c "from gmi.datasets.mnist import MNIST; print('MNIST works!')"
-
-# Test CLI command
-python main.py train-image-reconstructor examples/modular_configs/training_config.yaml
-
-# Test example script
-python examples/modular_configs/run_default_study.py
-```
-
-### 3. Debug Issues
-When you encounter errors:
-
-1. **Read the Stack Trace**: Look for file paths and line numbers
-2. **Identify the Problem**: Find the specific function/class causing issues
-3. **Edit the File**: Make changes on the host system
-4. **Test Again**: Run the same command to verify the fix
-5. **Iterate**: Repeat until the issue is resolved
-
-### 4. Run Examples
-Once components are working, run full examples:
-
-**From outside container:**
-```bash
-# Run modular studies
-docker exec -it gmi-container bash examples/modular_configs/run_all_studies_cli.sh
-
-# Run individual studies
-docker exec -it gmi-container python examples/modular_configs/run_all_modular_studies.py
-```
-
-**From inside container:**
-```bash
-# Run modular studies
-bash examples/modular_configs/run_all_studies_cli.sh
-
-# Run individual studies
-python examples/modular_configs/run_all_modular_studies.py
-```
-
-## Debugging Tips
-
-### 1. Check Container Status
-```bash
-# Verify container is running
-docker ps
-
-# Check container logs
-docker logs gmi-container
-```
-
-### 2. Interactive Debugging
-```bash
-# Start interactive Python session
-docker exec -it gmi-container python
-
-# Or start bash session
-docker exec -it gmi-container bash
-```
-
-### 3. File System
-- Files edited on host are immediately available in container
-- Container path: `/gmi_base/` (maps to your project root)
-- Working directory in container: `/gmi_base/`
-
-### 4. Common Issues
-- **Import Errors**: Check if module exists and is properly imported
-- **Path Issues**: Use relative paths from `/gmi_base/` in container
-- **Permission Issues**: Files should be readable by container user
-- **Memory Issues**: Large datasets may require more container memory
-
-## Project Structure
-
-```
-gmi/                          # Main package
-‚îú‚îÄ‚îÄ commands/                 # CLI commands
-‚îú‚îÄ‚îÄ datasets/                 # Dataset implementations
-‚îú‚îÄ‚îÄ network/                  # Neural network architectures
-‚îú‚îÄ‚îÄ tasks/                    # Training tasks
-‚îî‚îÄ‚îÄ ...
-
-examples/                     # Example scripts and configs
-‚îú‚îÄ‚îÄ modular_configs/         # Modular configuration system
-‚îÇ   ‚îú‚îÄ‚îÄ datasets/            # Dataset configs
-‚îÇ   ‚îú‚îÄ‚îÄ measurement_simulators/  # Noise configs
-‚îÇ   ‚îú‚îÄ‚îÄ image_reconstructors/    # Network configs
-‚îÇ   ‚îî‚îÄ‚îÄ run_*.py            # Example scripts
-‚îî‚îÄ‚îÄ ...
-
-main.py                      # CLI entry point
-requirements.txt             # Python dependencies
-Dockerfile                   # Container definition
-docker-compose.yml          # Container orchestration
-```
-
-## Best Practices
-
-1. **Test Incrementally**: Test small changes before running full examples
-2. **Use Stack Traces**: Always read error messages carefully
-3. **Check Imports**: Verify all imports work before running scripts
-4. **Monitor Resources**: Watch for memory/CPU usage in long-running tasks
-5. **Save Configs**: The system automatically saves final configs to experiment directories
-
-## Troubleshooting
-
-### Container Not Responding
-```bash
-# Restart container
-docker restart gmi-container
-
-# Check container status
-docker ps -a
-```
-
-### Permission Issues
-```bash
-# Check file permissions
-docker exec -it gmi-container ls -la /gmi_base/
-
-# Fix permissions if needed (run on host)
-chmod -R 755 .
-```
-
-### Memory Issues
-```bash
-# Check container resource usage
-docker stats gmi-container
-```
-
-### GPU Issues
-```bash
-# Check GPU availability in container
-docker exec -it gmi-container nvidia-smi
-
-# Check PyTorch CUDA support
-docker exec -it gmi-container python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
-```
-
-This development environment provides a controlled, reproducible setup for developing and testing the GMI package. The key is to understand that you're editing on the host but testing in the container, and the `docker exec` command is your bridge between the two. 
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 80a2c17..78af4f5 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -28,6 +28,12 @@ wandb>=0.13.0
 datasets>=2.10.0
 PyYAML>=6.0
 click>=8.0.0
+hydra-core>=1.3.0
 
 # Medical datasets
-medmnist>=1.0.0 
\ No newline at end of file
+medmnist>=1.0.0
+
+# Testing framework
+pytest>=7.0.0
+pytest-cov>=4.0.0
+pytest-mock>=3.10.0 
\ No newline at end of file
diff --git a/setup.py b/setup.py
index cdb547f..e8922f0 100644
--- a/setup.py
+++ b/setup.py
@@ -11,6 +11,13 @@ setup(
     install_requires=[
         # Dependencies are managed in requirements.txt
     ],
+    extras_require={
+        'dev': [
+            'pytest>=7.0.0',
+            'pytest-cov>=4.0.0',
+            'pytest-mock>=3.10.0',
+        ],
+    },
     entry_points={
         'console_scripts': [
             'gmi=main:cli',
